{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "from datascience import *\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plots\n",
    "plots.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some functions for plotting. You don't have to understand how any\n",
    "# of the functions in this cell work, since they use things we \n",
    "# haven't learned about in Data 8.\n",
    "\n",
    "\n",
    "def resize_window(lim=3.5):\n",
    "    plots.xlim(-lim, lim)\n",
    "    plots.ylim(-lim, lim)\n",
    "    \n",
    "def draw_line(slope=0, intercept=0, x=make_array(-4, 4), color='r'):\n",
    "    y = x*slope + intercept\n",
    "    plots.plot(x, y, color=color)\n",
    "    \n",
    "def draw_vertical_line(x_position, color='black'):\n",
    "    x = make_array(x_position, x_position)\n",
    "    y = make_array(-4, 4)\n",
    "    plots.plot(x, y, color=color)\n",
    "    \n",
    "def make_correlated_data(r):\n",
    "    x = np.random.normal(0, 1, 1000)\n",
    "    z = np.random.normal(0, 1, 1000)\n",
    "    y = r*x + (np.sqrt(1-r**2))*z\n",
    "    return x, y\n",
    "\n",
    "def r_scatter(r):\n",
    "    \"\"\"Generate a scatter plot with a correlation approximately r\"\"\"\n",
    "    plots.figure(figsize=(5,5))\n",
    "    x, y = make_correlated_data(r)\n",
    "    plots.scatter(x, y, color='darkblue', s=20)\n",
    "    plots.xlim(-4, 4)\n",
    "    plots.ylim(-4, 4)\n",
    "    \n",
    "def r_table(r):\n",
    "    \"\"\"\n",
    "    Generate a table of 1000 data points with a correlation approximately r\n",
    "    \"\"\"\n",
    "    np.random.seed(8)\n",
    "    x, y = make_correlated_data(r)\n",
    "    return Table().with_columns('x', x, 'y', y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression: defining the line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write code to implement linear regression, using the equations we've seen in class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_units(x):\n",
    "    \"\"\" Converts an array x to standard units \"\"\"\n",
    "    return (x - np.mean(x)) / np.std(x)\n",
    "\n",
    "def correlation(t, x, y):\n",
    "    \"\"\" Computes correlation: t is a table, and x and y are column names \"\"\"\n",
    "    x_su = standard_units(t.column(x))\n",
    "    y_su = standard_units(t.column(y))\n",
    "    return np.mean(x_su * y_su)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slope(t, x, y):\n",
    "    \"\"\" Computes the slope of the regression line, like correlation above \"\"\"\n",
    "    r = correlation(t, x, y)\n",
    "    y_sd = np.std(t.column(y))\n",
    "    x_sd = np.std(t.column(x))\n",
    "    return r * y_sd / x_sd\n",
    "\n",
    "def intercept(t, x, y):\n",
    "    \"\"\" Computes the intercept of the regression line, like slope above \"\"\"\n",
    "    x_mean = np.mean(t.column(x))\n",
    "    y_mean = np.mean(t.column(y))\n",
    "    return y_mean - slope(t, x, y)*x_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = r_table(0.5)\n",
    "slope(example, 'x', 'y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Galton height data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to apply this to the Galton dataset for predicting the height of children."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "galton = Table.read_table('galton.csv')\n",
    "\n",
    "heights = Table().with_columns(\n",
    "    'MidParent', galton.column('midparentHeight'),\n",
    "    'Child', galton.column('childHeight'))\n",
    "heights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_prediction_galton(h):\n",
    "    \"\"\"Return a prediction of the height of a child \n",
    "    whose parents have a midparent height of h.\n",
    "    \n",
    "    The prediction is the average height of the children \n",
    "    whose midparent height is in the range h plus or minus 0.5 inches.\n",
    "    \"\"\"\n",
    "    neighbors = heights.where(\n",
    "        'MidParent', are.between(h - 0.5, h + 0.5))\n",
    "    return np.mean(neighbors.column('Child'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heights_with_predictions = heights.with_column(\n",
    "    'Nearest neighbor prediction', \n",
    "    heights.apply(nn_prediction_galton, 'MidParent'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "galton_slope = slope(heights, 'MidParent', 'Child')\n",
    "galton_slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "galton_intercept = intercept(heights, 'MidParent', 'Child')\n",
    "galton_intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That gives us a linear regression model for predicting the height of the child from the height of the parents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heights.take(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll make a prediction for the height of the child of a couple whose parents have a midparent height of 69.48\", first using the nearest neighbor prediction, then using the linear regression model we computed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_prediction_galton(69.48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "galton_slope * 69.48 + galton_intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the graph of predictions, for both approaches to prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heights_with_predictions = heights_with_predictions.with_column(\n",
    "    'Regression prediction', \n",
    "    galton_slope*heights.column('MidParent') + galton_intercept\n",
    ")\n",
    "heights_with_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "heights_with_predictions.scatter('MidParent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression line vs other lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll work with another dataset, illustrating the relationship between median income and education level across the country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demographics_errors(slope, intercept):\n",
    "    # Use four convenient points from the original data\n",
    "    sample = [[14.7, 33995], [19.1, 61454], [50.7, 71183], [59.5, 105918]]\n",
    "    demographics.scatter('College%', 'Median Income', alpha=0.5)\n",
    "    xlims = make_array(5, 75)\n",
    "    # Plot a line with the slope and intercept you specified:\n",
    "    plots.plot(xlims, slope * xlims + intercept, lw=4)\n",
    "    # Plot red lines from each of the four points to the line\n",
    "    for x, y in sample:\n",
    "        plots.plot([x, x], [y, slope * x + intercept], color='r', lw=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitted_values(t, x, y):\n",
    "    \"\"\"Return an array of the regression estimates at all the x values\"\"\"\n",
    "    a = slope(t, x, y)\n",
    "    b = intercept(t, x, y)\n",
    "    return a*t.column(x) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "demographics = Table.read_table('district_demographics2016.csv')\n",
    "demographics.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "demographics = demographics.select('Median Income', 'College%')\n",
    "demographics.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics.scatter('College%', 'Median Income')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pause here for a moment to see what we can infer from this scatter plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use linear regression to infer a linear model to help us predict the median income of a congressional district, given the percentage of people with a college education."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation(demographics, 'College%', 'Median Income')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_slope = slope(demographics, 'College%', 'Median Income')\n",
    "regression_intercept = intercept(demographics, 'College%', 'Median Income')\n",
    "regression_slope, regression_intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = fitted_values(demographics, 'College%', 'Median Income')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics = demographics.with_column(\n",
    "    'Linear Prediction', predicted)\n",
    "demographics.scatter('College%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course the linear model is not perfect; there will typically be some errors in the predictions.  Let's measure how large those errors are, and visualize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = demographics.column('Median Income')\n",
    "errors = actual - predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics.with_column('Error', errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's tempting to measure the quality of a linear regression model by taking the average error.  However, this doesn't work: the average works out to zero, because the points above the line (where error is positive) are cancelled out by points below the line (where error is negative)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Side question: It looks like the average was a very small number, not exactly zero.  Can you guess why that happened?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intuitively, if your prediction is too large, that's as bad as if the prediction is too small.  So, it'd be natural to take the absolute value of the errors (to make them all positive, so they don't cancel each other out) and take the average of that.  But, for various reasons, instead we're going to take the square of the errors; that will also all make them positive and eliminate squaring.  (This might remind you of how we define the standard deviation.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(errors ** 2) ** 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "demographics_errors(regression_slope, regression_intercept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we tried a different line?  Then the errors would look different:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics_errors(1500, 20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics_errors(-1000, 75000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ugh.  That last line looked like a terrible fit to the data; the prediction errors it would make are huge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Root Mean Square Error ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's quantify that, by measuring the root-mean-square error.  A prediction line with a smaller root-mean-square error will tend to have a smaller prediction error, so smaller is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_demographics_rmse(slope, intercept):\n",
    "    demographics_errors(slope, intercept)\n",
    "    x = demographics.column('College%')\n",
    "    y = demographics.column('Median Income')\n",
    "    prediction = slope * x + intercept\n",
    "    mse = np.mean((y - prediction) ** 2)\n",
    "    print(\"Root mean squared error:\", round(mse ** 0.5, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_demographics_rmse(-1000, 75000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_demographics_rmse(1500, 20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_demographics_rmse(regression_slope, regression_intercept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of those lines had the lowest root-mean-square error?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical Optimization ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a bit of an aside.  We'll show you how to do numerical optimization.  In particular, if you have a function that computes how good a particular set of values are, numerical optimization will find the best values.  It will find inputs to the function that make the output of that function as small as possible.\n",
    "\n",
    "How does it work?  Magic.  OK, it's not really magic -- you can take more advanced classes where you learn how to do this -- but that's beyond the scope of this class.  For our purposes, we'll take it for granted that someone else has figured out how to do this, and we'll use it for our needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(1, 3, 0.1)\n",
    "y = (x-2)**2 + 3\n",
    "Table().with_columns('x', x, 'y', y).plot('x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return ((x-2)**2) + 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimize(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(-1.5, 1.5, 0.05)\n",
    "y2 = 2 * np.sin(x*np.pi) + x ** 3 + x ** 4 \n",
    "Table().with_columns('x', x, 'y', y2).plot('x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complicated_function(x):\n",
    "    return 2 * np.sin(x*np.pi) + x ** 3 + x ** 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimize(complicated_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimizing RMSE ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use numerical optimization to find the line (the slope and intercept) that minimize the root-mean-square prediction error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demographics_rmse(any_slope, any_intercept):\n",
    "    x = demographics.column('College%')\n",
    "    y = demographics.column('Median Income')\n",
    "    estimate = any_slope*x + any_intercept\n",
    "    return (np.mean((y - estimate) ** 2)) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics_rmse(1500, 20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics_rmse(-1000, 75000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimize(demographics_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_array(regression_slope, regression_intercept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool!  So the values that minimize the root-mean-square error, are exactly the ones that we computed using the formulas we showed you last lecture (using correlation and standard units).  This isn't an accident -- in fact, it always works out that way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nonlinear Regression ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A little bit of a digression: you can also use numerical optimization to make predictions when there is a nonlinear association among the data, if you have an idea for the nature of the association.  We'll work with a dataset that measures, for a bunch of athletes, how many kilograms they can lift, and how far they can throw a shot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shotput = Table.read_table('shotput.csv')\n",
    "shotput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shotput.scatter('Weight Lifted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can fit a linear regression model to this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shotput_linear_rmse(any_slope, any_intercept):\n",
    "    x = shotput.column('Weight Lifted')\n",
    "    y = shotput.column('Shot Put Distance')\n",
    "    estimate = any_slope*x + any_intercept\n",
    "    return np.mean((y - estimate) ** 2) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_line = minimize(shotput_linear_rmse)\n",
    "best_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = shotput.column(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_fit = best_line.item(0)*weights + best_line.item(1)\n",
    "\n",
    "shotput.with_column(\n",
    "    'Best Line', linear_fit\n",
    ").scatter(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ugh.  That doesn't look like a very good fit.  You can see the predictions are systematically too low, on the left end.  The study that gathered this data hypothesized that there should be a quadratic relationship between weight lighted and shot put distance, so instead of fitting a line, let's fit a parabola -- a quadratic equation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **quadratic Function** is given by the equation\n",
    "\n",
    "$$\n",
    "f(x) ~=~ ax^2 + bx + c\n",
    "$$\n",
    "for constants $a$, $b$, and $c$.  Let's try to find constants $a,b,c$ that yield a good fit to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shotput_quadratic_rmse(a, b, c):\n",
    "    x = shotput.column('Weight Lifted')\n",
    "    y = shotput.column('Shot Put Distance')\n",
    "    estimate = a*(x**2) + b*x + c\n",
    "    return np.mean((y - estimate) ** 2) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_quad = minimize(shotput_quadratic_rmse)\n",
    "best_quad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = weight lifted = 100 kg\n",
    "# Then predicted shot put distance:\n",
    "\n",
    "(-0.00104)*(100**2) + 0.2827*100 - 1.5318"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quad_fit = best_quad.item(0)*(weights**2) + best_quad.item(1)*weights + best_quad.item(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shotput.with_column('Best Quadratic Curve', quad_fit).scatter(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
