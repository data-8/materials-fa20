{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize OK\n",
    "from client.api.notebook import Notebook\n",
    "ok = Notebook('hw11.ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 11: Regression Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Helpful Resource:**\n",
    "- [Python Reference](http://data8.org/fa20/python-reference.html): Cheat sheet of helpful array & table methods used in Data 8!\n",
    "\n",
    "**Reading**: \n",
    "* [Inference for Regression](https://www.inferentialthinking.com/chapters/16/Inference_for_Regression.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please complete this notebook by filling in the cells provided. Before you begin, execute the following cell to load the provided tests. Each time you start your server, you will need to execute this cell again to load the tests.\n",
    "\n",
    "For all problems that you must write explanations and sentences for, you **must** provide your answer in the designated space. **Moreover, throughout this homework and all future ones, please be sure to not re-assign variables throughout the notebook!** For example, if you use `max_temperature` in your answer to one question, do not reassign it later on. Otherwise, you will fail tests that you thought you were passing previously!\n",
    "\n",
    "**Deadline:**\n",
    "\n",
    "This assignment is due Friday, November 20 at 11:59 P.M. PST. You will receive an early submission bonus point if you turn in your final submission by Thursday, November 19 at 11:59 P.M. PST. Late work will not be accepted as per the [policies](http://data8.org/fa20/policies.html) page. From here on out, homeworks will have an automatic 1-day extension applied, so they will be due on **Fridays**, with an early submission bonus point for submitting on **Thursdays**.\n",
    "\n",
    "**Note: This homework has hidden tests on it. That means even though tests may say 100% passed, doesn't mean your final grade will be 100%. We will be running more tests for correctness once everyone turns in the homework.**\n",
    "\n",
    "Directly sharing answers is not okay, but discussing problems with the course staff or with other students is encouraged. Refer to the policies page to learn more about how to learn cooperatively.\n",
    "\n",
    "You should start early so that you have time to get help if you're stuck. Office hours are held Monday-Friday. The schedule appears on [http://data8.org/fa20/office-hours.html](http://data8.org/fa20/office-hours.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Don't change this cell; just run it. \n",
    "\n",
    "import numpy as np\n",
    "from datascience import *\n",
    "\n",
    "# These lines do some fancy plotting magic.\",\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', FutureWarning)\n",
    "\n",
    "from client.api.notebook import *\n",
    "def new_save_notebook(self):\n",
    "    \"\"\" Saves the current notebook by\n",
    "        injecting JavaScript to save to .ipynb file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        from IPython.display import display, Javascript\n",
    "    except ImportError:\n",
    "        log.warning(\"Could not import IPython Display Function\")\n",
    "        print(\"Make sure to save your notebook before sending it to OK!\")\n",
    "        return\n",
    "\n",
    "    if self.mode == \"jupyter\":\n",
    "        display(Javascript('IPython.notebook.save_checkpoint();'))\n",
    "        display(Javascript('IPython.notebook.save_notebook();'))\n",
    "    elif self.mode == \"jupyterlab\":\n",
    "        display(Javascript('document.querySelector(\\'[data-command=\"docmanager:save\"]\\').click();'))   \n",
    "\n",
    "    print('Saving notebook...', end=' ')\n",
    "\n",
    "    ipynbs = [path for path in self.assignment.src\n",
    "              if os.path.splitext(path)[1] == '.ipynb']\n",
    "    # Wait for first .ipynb to save\n",
    "    if ipynbs:\n",
    "        if wait_for_save(ipynbs[0]):\n",
    "            print(\"Saved '{}'.\".format(ipynbs[0]))\n",
    "        else:\n",
    "            log.warning(\"Timed out waiting for IPython save\")\n",
    "            print(\"Could not automatically save \\'{}\\'\".format(ipynbs[0]))\n",
    "            print(\"Make sure your notebook\"\n",
    "                  \" is correctly named and saved before submitting to OK!\".format(ipynbs[0]))\n",
    "            return False                \n",
    "    else:\n",
    "        print(\"No valid file sources found\")\n",
    "    return True\n",
    "\n",
    "def wait_for_save(filename, timeout=600):\n",
    "    \"\"\"Waits for FILENAME to update, waiting up to TIMEOUT seconds.\n",
    "    Returns True if a save was detected, and False otherwise.\n",
    "    \"\"\"\n",
    "    modification_time = os.path.getmtime(filename)\n",
    "    start_time = time.time()\n",
    "    while time.time() < start_time + timeout:\n",
    "        if (os.path.getmtime(filename) > modification_time and\n",
    "            os.path.getsize(filename) > 0):\n",
    "            return True\n",
    "        time.sleep(0.2)\n",
    "    return False\n",
    "\n",
    "Notebook.save_notebook = new_save_notebook\n",
    "\n",
    "ok = Notebook('hw11.ok')\n",
    "_ = ok.auth(inline=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before continuing the assignment, select \"Save and Checkpoint\" in the File menu and then execute the submit cell below. The result will contain a link that you can use to check that your assignment has been submitted successfully. If you submit more than once before the deadline, we will only grade your final submission. If you mistakenly submit the wrong one, you can head to okpy.org and flag the correct version. There will be another submit cell at the end of the assignment when you finish!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ok.submit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Regression Inference for the NFL Draft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this homework, we will be analyzing the relationship between draft position and success in the NFL. The NFL draft is an annual event in which every NFL team takes turns choosing players that they will add to their team. There are around 200 selections, called \"picks\" made every year, although this number has changed over the years.\n",
    "\n",
    "The `nfl_data` table has five columns, the name of the `Player`, the `Salary` that player made for the 2019 season, the year that player was drafted (`Year Drafted`), the number of the draft pick that was used when the player was drafted (`Pick Number`), and the `Position` in football that player plays.\n",
    "\n",
    "Each row in `nfl_data` corresponds to one player who played in the **2019 season**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Just run this cell!\n",
    "nfl_data = Table.read_table(\"nfl.csv\")\n",
    "nfl_data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Question 1\n",
    "\n",
    "Take the `nfl_data` table and add a column called `Career Length` that corresponds to how long a player has been in the NFL to create a new table called `nfl`. `Career Length` is from when they were drafted to this year, 2020. So, if a player was drafted in 2015, their career length is 5:\n",
    "$$2020-2015=5$$\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_1\n",
    "manual: false\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "for_assignment_type": "student"
   },
   "outputs": [],
   "source": [
    "nfl = ...\n",
    "nfl.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q1_1\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, let's investigate our data visually before analyzing it numerically. The first relationship we will analyze is the relationship between a player's `Pick Number` and their `Career Length`. Run the following cell to see a scatter diagram with the line of best fit plotted for you in red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Just run this cell\n",
    "nfl.scatter(\"Pick Number\", \"Career Length\")\n",
    "m, b = np.polyfit(nfl.column(3), nfl.column(5), 1)\n",
    "plt.plot(nfl.column(3), m*nfl.column(3)+b, color='r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Question 2\n",
    "\n",
    "Use the functions given to assign the correlation between `Pick Number` and `Career Length` to `pick_length_correlation`. `correlation` takes in three arguments, a table `tbl` and the labels of the columns you are finding the correlation between, `col1` and `col2`.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_2\n",
    "manual: false\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-04T09:57:57.365938Z",
     "start_time": "2018-04-04T09:57:57.357879Z"
    },
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def standard_units(arr):\n",
    "    return (arr- np.mean(arr)) / np.std(arr)\n",
    "\n",
    "def correlation(tbl, col1, col2):\n",
    "    r = np.mean(standard_units(tbl.column(col1)) * standard_units(tbl.column(col2)))\n",
    "    return r\n",
    "\n",
    "pick_length_correlation = ...\n",
    "pick_length_correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q1_2\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there is a negative association between `Pick Number` and `Career Length`! If in the sample, we found a linear relation between the two variables, would the same be true for the population? Would it be exactly the same linear relation? Could we predict the response of a new individual who is not in our sample? \n",
    "\n",
    "Let's find out the answers to these questions by investigating whether there is a true linear relation or correlation in the population between `Pick Number` and `Career Length`!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Question 3\n",
    "\n",
    "Evan thinks that the slope of the true line of best fit for `Pick Number` and `Career Length` is not zero: that is, there is some correlation/association between `Pick Number` and `Career Length`. To test this claim, we can run a hypothesis test! Define the null and alternative hypothesis for this test.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_3\n",
    "manual: true\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "export_pdf": true
   },
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Question 4\n",
    "\n",
    "Saurav says that instead of finding the slope for each resample, we can find the correlation instead, and that we will get the same result for the hypothesis test. Why is he correct? What is the relationship between slope and correlation?\n",
    "\n",
    "*Hint: This [section](https://www.inferentialthinking.com/chapters/15/2/Regression_Line.html) of the textbook describes the relationship between slope and correlation.*\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_4\n",
    "manual: true\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "export_pdf": true
   },
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Question 5\n",
    "Define the function `one_resample_r` that performs a bootstrap and finds the correlation between `Pick Number` and `Career Length` in the resample. `one_resample_r` should take three arguments, a table `tbl` and the labels of the columns you are finding the correlation between, `col1` and `col2`.\n",
    "\n",
    "*Hint: You can use previously defined functions to help you.*\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_5\n",
    "manual: false\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "manual_problem_id": "crypto_5"
   },
   "outputs": [],
   "source": [
    "def one_resample_r(tbl, col1, col2):\n",
    "    ...\n",
    "\n",
    "# Don't change this line below!\n",
    "one_resample = one_resample_r(nfl, \"Pick Number\", \"Career Length\")\n",
    "one_resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q1_5\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Question 6\n",
    "\n",
    "Generate 1000 bootstrapped correlations for `Pick Number` and `Career Length`, store your results in the array `resampled_correlations_pc`, and plot a histogram of your results.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_6\n",
    "manual: true\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "export_pdf": true
   },
   "outputs": [],
   "source": [
    "resampled_correlations_pc = ...\n",
    "...\n",
    "\n",
    "# Don't change the following line of code. It will plot your histogram.\n",
    "Table().with_column(\"Resampled Correlations, Pick Number vs Career Length\", resampled_correlations_pc).hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Question 7\n",
    "\n",
    "Calculate a 95% confidence interval for the resampled correlations and then assign either `True` or `False` to `reject` if we can reject the null hypothesis or if we cannot reject the null hypothesis using a 5% p-value cutoff.\n",
    "\n",
    "*Note: Feel free to calculate the CI first, then fill in the `reject` variable after.*\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_7\n",
    "manual: false\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_bound_pc = ...\n",
    "upper_bound_pc = ...\n",
    "reject = ...\n",
    "\n",
    "# Don't change this!\n",
    "print(f\"95% CI: [{lower_bound_pc}, {upper_bound_pc}] , Reject the null: {reject}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q1_7\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's investigate the relationship between `Pick Number` and `Salary`. As usual, let's inspect our data visually first. A line of best fit is plotted for you in red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Just run this cell!\n",
    "nfl.scatter(\"Pick Number\", \"Salary\")\n",
    "c, d = np.polyfit(nfl.column(3), nfl.column(1), 1)\n",
    "plt.plot(nfl.column(3), c*nfl.column(3)+d, color='r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Question 8\n",
    "\n",
    "Using the function `correlation`, find the correlation between `Pick Number` and `Salary` and assign it to `pick_salary_correlation`.\n",
    "\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_8\n",
    "manual: false\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pick_salary_correlation = ...\n",
    "pick_salary_correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q1_8\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there is a negative association between `Pick Number` and `Salary`! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Question 9\n",
    "\n",
    "Once again, Evan thinks that the slope of the true line of best fit for `Pick Number` and `Salary` is not zero: that is, there is some correlation/association between `Pick Number` and `Salary`. To test this claim, we can run a hypothesis test! Define the null and alternative hypothesis for this test.\n",
    "\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_9\n",
    "manual: true\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "export_pdf": true
   },
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Question 10\n",
    "\n",
    "Generate 1000 bootstrapped correlations for `Pick Number` and `Salary`, append them to the array `resampled_correlations_salary`, and then plot a histogram of your results.\n",
    "\n",
    "*Hint: Your code for this question will be similar to Question 6.*\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_10\n",
    "manual: true\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "export_pdf": true
   },
   "outputs": [],
   "source": [
    "resampled_correlations_salary = ...\n",
    "...\n",
    "\n",
    "# Don't change the following line of code. It will plot your histogram.\n",
    "Table().with_column(\"Resampled Correlations for Salary\", resampled_correlations_salary).hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Question 11\n",
    "\n",
    "Calculate a 95% confidence interval for the resampled correlations and then assign either `True` or `False` to `reject_sal` if we can reject the null hypothesis or if we cannot reject the null hypothesis using a 5% p-value cutoff.\n",
    "\n",
    "*Note: Feel free to calculate the CI first, then fill in the `reject_sal` variable after.*\n",
    "\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_11\n",
    "manual: false\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_bound_sal = ...\n",
    "upper_bound_sal = ...\n",
    "reject_sal = ...\n",
    "\n",
    "# Don't change this!\n",
    "print(f\"95% CI: [{lower_bound_sal}, {upper_bound_sal}], Reject the null: {reject_sal}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q1_11\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Analyzing Residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, Evan wants to predict his Career Length and Salary based on his Pick Number. To understand what his Career Length and Salary might be, Evan wants to generate confidence intervals of possible values for both career length and salary. First, let's investigate how effective our predictions for career length and salary based on pick number are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Question 12\n",
    "\n",
    "Calculate the slope and intercept for the line of best fit for `Pick Number` vs `Career Length` and for `Pick Number` vs `Salary`. Assign these values to `career_length_slope`, `career_length_intercept`, `salary_slope`, and `salary_intercept` respectively. The function `parameters` returns a two-item array containing the slope and intercept of a linear regression line.\n",
    "\n",
    "*Hint 1: Use the `parameters` function with the arguments specified!*\n",
    "\n",
    "*Hint 2: Remember we're predicting career length and salary **based off** a pick number. That should tell you what the `colx` and `coly` arguments you should specify when calling `parameters`.*\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_12\n",
    "manual: false\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DON'T EDIT THE PARAMETERS FUNCTION\n",
    "def parameters(tbl, colx, coly):\n",
    "    x = tbl.column(colx)\n",
    "    y = tbl.column(coly)\n",
    "    \n",
    "    r = correlation(tbl, colx, coly)\n",
    "    \n",
    "    x_mean = np.mean(x)\n",
    "    y_mean = np.mean(y)\n",
    "    x_sd = np.std(x)\n",
    "    y_sd = np.std(y)\n",
    "    \n",
    "    slope = (y_sd / x_sd) * r\n",
    "    intercept = y_mean - (slope * x_mean)\n",
    "    return make_array(slope, intercept)\n",
    "\n",
    "career_length_slope = ...\n",
    "career_length_intercept = ...\n",
    "\n",
    "salary_slope = ...\n",
    "salary_intercept = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q1_12\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Question 13\n",
    "\n",
    "Draw a scatter plot of the residuals (i.e. actual - predicted) for each line of best fit for `Pick Number` vs `Career Length` and for `Pick Number` vs `Salary`. \n",
    "\n",
    "*Hint: We want to get the predictions for every player in the dataset*\n",
    "\n",
    "*Hint 2: This question is really involved, try to follow the skeleton code! This [section](https://www.inferentialthinking.com/chapters/15/5/Visual_Diagnostics.html) of the textbook will be helpful for the next two questions.*\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_13\n",
    "manual: true\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "export_pdf": true
   },
   "outputs": [],
   "source": [
    "predicted_career_lengths = ...\n",
    "predicted_salaries = ...\n",
    "\n",
    "career_length_residuals = ...\n",
    "salary_residuals = ...\n",
    "\n",
    "nfl_with_residuals = nfl.with_columns(\"Career Length Residuals\", career_length_residuals, \"Salary Residuals\", salary_residuals)\n",
    "\n",
    "# Now generate two scatter plots!\n",
    "nfl_with_residuals.scatter(\"Pick Number\", \"Career Length Residuals\")\n",
    "nfl_with_residuals.scatter(\"Pick Number\", \"Salary Residuals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a [link](https://www.inferentialthinking.com/chapters/15/6/Numerical_Diagnostics.html) to properties of residuals in the textbook that could help out with some questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Question 14\n",
    "\n",
    "Based on these plots of residuals, do you think linear regression is a good model for `Pick Number` vs `Career Length` and for `Pick Number` vs `Salary`? Explain for both.\n",
    "\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_14\n",
    "manual: true\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "export_pdf": true
   },
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Question 15\n",
    "\n",
    "Assign `career_length_residual_corr` and `salary_residual_corr` to either 1, 2 or 3 corresponding to whether or not the correlation between `Pick Number` and `Career Length Residuals` is zero, positive, or negative, and to whether or not the correlation between `Pick Number` and `Salary Residuals` is zero, positive, or negative respectively.\n",
    "\n",
    "*Hint: This [section](https://www.inferentialthinking.com/chapters/15/6/Numerical_Diagnostics.html) of the textbook will be helpful.*\n",
    "\n",
    "1. Zero\n",
    "2. Positive\n",
    "3. Negative\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_15\n",
    "manual: false\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "career_length_residual_corr = ...\n",
    "salary_residual_corr = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q1_15\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the largest residuals are positive residuals, so let's investigate those more closely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Question 16\n",
    "\n",
    "Let's investigate where our regression line is making errors. Using the `nfl_with_residuals` table, assign `greatest_career_length_residual` to the string that is the name of the player with the largest positive residual for `Pick Number` vs `Career Length`.\n",
    "\n",
    "*Hint: We would recommend running `nfl_with_residuals` in a separate cell to see what the table looks like.*\n",
    "\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_16\n",
    "manual: false\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "greatest_career_length_residual = ...\n",
    "greatest_career_length_residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q1_16\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's investigate the residuals for salary. Run the cell below to see the players with the largest residuals for `Pick Number` vs `Salary`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Just run this cell!\n",
    "nfl_with_residuals.sort(\"Salary Residuals\", descending=True).take(np.arange(10)).drop(2,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Question 17\n",
    "\n",
    "What patterns do you notice with these large residuals for salary? How could this affect our analysis?\n",
    "\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_17\n",
    "manual: true\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "export_pdf": true
   },
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Prediction Intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, Evan wants to predict his career length based on his specific pick number, which is 169. Instead of using the best fit line generated from the sample, Evan wants to generate an interval for his predicted career length."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Question 18\n",
    "\n",
    "Define the function `one_resample_prediction` that generates a bootstrapped sample from the `tbl` argument, calculates the line of best fit for `coly` vs `colx` for that resample, and predicts a value based on `xvalue`.\n",
    "\n",
    "*Hint: The standard form of the line of best fit is y = mx+b, with a unique slope (m) and intercept (b) for our data. Remember, the `parameters` function was defined earlier to help find that slope and intercept!*\n",
    "\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_18\n",
    "manual: false\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_resample_prediction(tbl, colx, coly, xvalue):\n",
    "    ...\n",
    "\n",
    "evans_career_length_pred = one_resample_prediction(nfl, \"Pick Number\", \"Career Length\", 169)\n",
    "evans_career_length_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q1_18\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Question 19\n",
    "\n",
    "Assign `resampled_predictions` to be an array that will contain 1000 resampled predictions for Evan's career length based on his pick number 169, and then generate a histogram of it.\n",
    "\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_19\n",
    "manual: true\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "export_pdf": true
   },
   "outputs": [],
   "source": [
    "resampled_predictions = ...\n",
    "\n",
    "...\n",
    "\n",
    "# Don't change/delete the code below in this cell\n",
    "Table().with_column(\"Resampled Career Length Predictions\", resampled_predictions).hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Question 20\n",
    "\n",
    "Using `resampled_predictions` from Question 19, generate a 99% confidence interval for Evan's predicted career lengths.\n",
    "\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_20\n",
    "manual: false\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_bound_evan = ...\n",
    "upper_bound_evan = ...\n",
    "\n",
    "# Don't delete/modify the code below in this cell\n",
    "print(f\"99% CI: [{lower_bound_evan}, {upper_bound_evan}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q1_20\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to see a few bootstrapped regression lines, and the predictions they make for a career length from a pick number of 169."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Just run this cell! \n",
    "# You don't need to understand all of what it is doing but you should recognize a lot of the code!\n",
    "lines = Table(['slope','intercept'])\n",
    "x=169\n",
    "for i in np.arange(20):\n",
    "    resamp = nfl.sample(with_replacement=True)\n",
    "    resample_pars = parameters(resamp, \"Pick Number\", \"Career Length\") \n",
    "    slope = resample_pars.item(0)\n",
    "    intercept = resample_pars.item(1)\n",
    "    lines.append([slope, intercept])\n",
    "    \n",
    "lines['prediction at x='+str(x)] = lines.column('slope')*x + lines.column('intercept')\n",
    "xlims = [min(nfl.column(\"Pick Number\")), max(nfl.column(\"Pick Number\"))]\n",
    "left = xlims[0]*lines[0] + lines[1]\n",
    "right = xlims[1]*lines[0] + lines[1]\n",
    "fit_x = x*lines['slope'] + lines['intercept']\n",
    "for i in range(20):\n",
    "    plt.plot(xlims, np.array([left[i], right[i]]), lw=1)\n",
    "    plt.scatter(x, fit_x[i], s=30)\n",
    "plt.ylabel(\"Career Length\");\n",
    "plt.xlabel(\"Pick Number\");\n",
    "plt.title(\"Resampled Regression Lines\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Question 21\n",
    "\n",
    "Does the Central Limit Theorem guarantee that the bootstrapped slopes or bootstrapped correlations will be normally distributed for any dataset that uses a large random sample? If you think yes, assign `True` to `clt_applies`, otherwise assign `False` to `clt_applies` if you think no. Are residuals normally distributed? If you think they are, assign `True` to `residuals_normal`, otherwise assign `False` to `residuals_normal`.\n",
    "\n",
    "Hint: Remember what the CLT is defined for.\n",
    "\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_21\n",
    "manual: false\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "clt_applies = ...\n",
    "residuals_normal = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q1_21\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Question 22\n",
    "\n",
    "What are some biases in this dataset that may have affected our analysis? Some questions you can ask yourself are: \"is our sample a simple random sample?\" or \"what kind of data are we using/what variables are we dealing with: are they categorical, numerical, or both (both is something like ordinal data)?\".\n",
    "\n",
    "*Hint: you might want to revisit the beginning of this assignment to reread how this data/`nfl` table was generated.*\n",
    "\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_22\n",
    "manual: true\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "export_pdf": true
   },
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: Remember to run the ok.submit cell at the very bottom of this notebok to submit!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (OPTIONAL, Out of Scope) Extending Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This following section is completely **optional**, meaning there's no code to be graded/filled in. Just run the cells/explore if you're interested.\n",
    "\n",
    "In the past few weeks you have learned one of the most powerful tools in a data scientist's arsenal: regression. At this point you may be wondering: what do we do when our data is not linear? You have learned that you shouldn't try and force models when they are bad fits: for example, if we detect heteroscedasticity in our residuals plot, we know that linear regression is a bad fit.\n",
    "\n",
    "How can we fit data that is not linear then?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's increase our data's complexity a little: instead of linear data, let's look at data that you would naturally model with a parabola instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parabola(x, a=1, b=0, c=0):\n",
    "    random_noise = np.random.normal(size=len(x)) * 3\n",
    "    return  a*(x**2) + b*(x) + c + random_noise\n",
    "\n",
    "size = 500\n",
    "x_values = np.random.uniform(-5, 10, size=size)\n",
    "y_values = parabola(x_values, a=2, b=-3, c=5)\n",
    "\n",
    "Table().with_columns(\"X\", x_values, \"Y\", y_values).scatter(\"X\",\"Y\", fit_line=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that our line of best fit is a poor match for this data. Let's look at the residual plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(slope, intercept):\n",
    "    predicted_y = slope * x_values + intercept\n",
    "    errors = y_values - predicted_y\n",
    "    return np.mean(errors**2)\n",
    "\n",
    "\n",
    "slope_and_intercept = minimize(mse, smooth=True)\n",
    "predicted_y = slope_and_intercept.item(0) * x_values + slope_and_intercept.item(1)\n",
    "residuals = y_values - predicted_y\n",
    "\n",
    "Table().with_columns(\"X\", x_values, \"Residuals\",residuals).scatter(\"X\", \"Residuals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our residuals clearly have a pattern, confirming that linear regression is a bad fit for this data! In fact, our residuals actually look like our original data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression generates a line that minimizes mean squared error. Using the `minimize` function on the `mse` function does all the work of finding values for us! Can we use `minimize` for more complicated models? Yes! In future data science classes, you will learn how to find these values yourself using the mathematical fields of Linear Algebra (note that it involves lines!) and calculus!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the equation for a line:\n",
    "\n",
    "$$y = ax +b$$\n",
    "\n",
    "There are two parameters here that we can change: $a$, which is the slope, and $b$, which is the intercept.\n",
    "\n",
    "How about the equation for a parabola?\n",
    "\n",
    "$$y = ax^2 + bx + c$$\n",
    "\n",
    "Now there are three parameters, $a,b,c$.\n",
    "\n",
    "Let's change our mse function to incorporate these three parameters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_parabola(a, b, c):\n",
    "    predicted_y = a * (x_values**2) + b * (x_values) + c\n",
    "    errors = y_values - predicted_y\n",
    "    return np.mean(errors**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function still returns the mean squared error of our predicted curve, just our curve is now a parabola with the parameters `a`, `b`, and `c`. Let's try and minimize this function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = minimize(mse_parabola, smooth=True)\n",
    "a = params.item(0)\n",
    "b = params.item(1)\n",
    "c = params.item(2)\n",
    "a, b, c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot our new curve with these values!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_values_range = np.linspace(-5, 10, 1000)\n",
    "predicted_y = a * (x_values_range**2) + b * (x_values_range) + c\n",
    "\n",
    "Table().with_columns(\"X\", x_values, \"Y\", y_values).scatter(\"X\", \"Y\")\n",
    "plt.plot(x_values_range, predicted_y, color='gold', markersize=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our curve looks like a much better fit now! Let's double check the residuals plot to be sure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = y_values - (a * (x_values**2) + b * (x_values) + c)\n",
    "Table().with_columns(\"X\", x_values, \"Residuals\", residuals).scatter(\"X\", \"Residuals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A formless cloud, excellent!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What else can the method of least squares do?\n",
    "\n",
    "Can we predict a single variable based on the values of two other variables? Right now, we don't have a way of doing that. \n",
    "\n",
    "If you look at the previous example, you could say that the $x^2$ term is actually a second variable.\n",
    "\n",
    "Let's generate a dataset to work with. We are going to try and predict `z` based on `x` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_values_range = np.linspace(-5, 10, 1000)\n",
    "\n",
    "x = 0.5 * np.random.uniform(-5, 10, size=size) + 3\n",
    "y = np.random.uniform(-5, 10, size=size) - 1\n",
    "z = 3*x  + (-2*y) -4 + np.random.normal(size=size)\n",
    "\n",
    "data = Table().with_columns(\"x\", x, \"y\", y, \"z\", z)\n",
    "data.scatter(\"x\", \"y\")\n",
    "data.scatter(\"x\", \"z\")\n",
    "data.scatter(\"y\", \"z\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that `x` and `y` would both be very helpful to predict `z` by themselves! However, if we combined them we could predict `z` even better. Since our goal is to minimize mean squared error, let's find the mean squared error of the models that only use `x` and `y` by themselves (using an intercept)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "def su(x):\n",
    "    return (x-np.mean(x)) / np.std(x)\n",
    "def r(x, y):\n",
    "    return np.mean(su(x) * su(y))\n",
    "\n",
    "def mse_x(slope, intercept):\n",
    "    predicted_z = slope * x + intercept\n",
    "    errors = z - predicted_z\n",
    "    return np.mean(errors**2)\n",
    "\n",
    "def mse_y(slope, intercept):\n",
    "    predicted_z = slope * y + intercept\n",
    "    errors = z - predicted_z\n",
    "    return np.mean(errors**2)\n",
    "\n",
    "\n",
    "slope_and_intercept_x = minimize(mse_x, smooth=True)\n",
    "predicted_z_x = slope_and_intercept_x.item(0) * x + slope_and_intercept_x.item(1)\n",
    "residuals_x = z - predicted_z_x\n",
    "\n",
    "Table().with_columns(\"X\", x, \"Residuals for X Model\", residuals_x).scatter(\"X\", \"Residuals for X Model\")\n",
    "\n",
    "slope_and_intercept_y = minimize(mse_y, smooth=True)\n",
    "predicted_z_y = slope_and_intercept_y.item(0) * y + slope_and_intercept_y.item(1)\n",
    "residuals_y = z - predicted_z_y\n",
    "\n",
    "Table().with_columns(\"Y\", y, \"Residuals for Y Model\", residuals_y).scatter(\"Y\", \"Residuals for Y Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both of the residual plots show no trend, so using these `x` or `y` by themselves would work, but how good are these models? Let's calculate their actual mse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_only_mse = mse_x(slope_and_intercept_x.item(0), slope_and_intercept_x.item(1))\n",
    "y_only_mse = mse_y(slope_and_intercept_y.item(0), slope_and_intercept_y.item(1))\n",
    "\n",
    "print(f\"X only model MSE: {x_only_mse}, Y only model MSE: {y_only_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the y only model has lower MSE, so we should try and use that if we can only use `x` or `y`. \n",
    "\n",
    "Instead, let's try to build a model that is a combination of `x`, `y` and an intercept `c` to predict `z`!\n",
    "\n",
    "$$z = ax + by +c$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_both(a, b, c):\n",
    "    predicted_z = (a * x) + (b * y) + c\n",
    "    errors = z - predicted_z\n",
    "    return np.mean(errors**2)\n",
    "\n",
    "slope_and_intercept_both = minimize(mse_both, smooth=True)\n",
    "predicted_z = (slope_and_intercept_both.item(0) * x) + (slope_and_intercept_both.item(1) * y) + slope_and_intercept_both.item(2)\n",
    "residuals = z - predicted_z\n",
    "\n",
    "Table().with_columns(\"X\", x, \"Residuals for Full Model\", residuals).scatter(\"X\", \"Residuals for Full Model\")\n",
    "Table().with_columns(\"Y\", x, \"Residuals for Full Model\", residuals).scatter(\"Y\", \"Residuals for Full Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is also a good fit looking at the residuals with respect to both `x` and `y`! What is this model's mse?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model_mse = mse_both(slope_and_intercept_both.item(0), slope_and_intercept_both.item(1), slope_and_intercept_both.item(2))\n",
    "\n",
    "print(f\"X only model MSE: {x_only_mse}, Y only model MSE: {y_only_mse}, Both X and Y MSE: {full_model_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That MSE is much lower! We should definitely use this model instead of either the x only or y only model independently!\n",
    "Let's try and visualize what this model looks like with a 3D graph!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : False})\n",
    "\n",
    "fig = plt.figure(figsize=(10,7));\n",
    "ax = fig.add_subplot(111, projection='3d');\n",
    "ax.scatter(x, y, z);\n",
    "ax.set_xlabel('X');\n",
    "ax.set_ylabel('Y');\n",
    "ax.set_zlabel('Z');\n",
    "\n",
    "ax.scatter(x,y,predicted_z)\n",
    "ax.view_init(elev=20, azim=70);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we start working in more dimensions, visualization becomes increasingly difficult and useless. Instead of predicting a line, our prediction is actually a plane of values (the red values)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Submission\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Once you're finished, select \"Save and Checkpoint\" in the File menu and then execute the `submit` cell below. The result will contain a link that you can use to check that your assignment has been submitted successfully. If you submit more than once before the deadline, we will only grade your final submission. If you mistakenly submit the wrong one, you can head to [okpy.org](https://okpy.org/) and flag the correct version. To do so, go to the website, click on this assignment, and find the version you would like to have graded. There should be an option to flag that submission for grading!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_ = ok.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For your convenience, you can run this cell to run all the tests at once!\n",
    "import os\n",
    "print(\"Running all tests...\")\n",
    "_ = [ok.grade(q[:-3]) for q in os.listdir(\"tests\") if q.startswith('q') and len(q) <= 10]\n",
    "print(\"Finished running all tests.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
